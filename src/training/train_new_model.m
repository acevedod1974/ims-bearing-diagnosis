% train_new_model.m
% Entrenar un nuevo modelo Random Forest con datos personalizados
% Compatible con MATLAB R2020a+
%
% ANTES DE EJECUTAR:
%   1. AsegÃºrate de haber ejecutado prepare_training_data.m
%   2. Verifica que training_dataset.mat exista

clear; clc; close all;

fprintf('\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n');
fprintf('â•‘    ENTRENAMIENTO DE NUEVO MODELO RF       â•‘\n');
fprintf('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n');

%% ========================================================================
%  PASO 1: Cargar dataset de entrenamiento
%  ========================================================================
fprintf('PASO 1: Cargando dataset...\n');

if ~isfile('training_dataset.mat')
    error(['Dataset no encontrado.\n', ...
           'Ejecuta primero: run(''prepare_training_data.m'')']);
end

load('training_dataset.mat', 'features', 'labels');

fprintf('  âœ“ Dataset cargado: %d muestras\n', size(features, 1));

%% ========================================================================
%  PASO 2: Dividir datos en entrenamiento y validaciÃ³n
%  ========================================================================
fprintf('\nPASO 2: Dividiendo datos (70%% entrenamiento, 30%% validaciÃ³n)...\n');

% Convertir etiquetas a categorical
labels_cat = categorical(labels);

% DivisiÃ³n estratificada (mantiene proporciones de clases)
cv = cvpartition(labels_cat, 'HoldOut', 0.3);

% Conjuntos de entrenamiento
X_train = features(training(cv), :);
y_train = labels_cat(training(cv));

% Conjuntos de validaciÃ³n
X_test = features(test(cv), :);
y_test = labels_cat(test(cv));

fprintf('  âœ“ Entrenamiento: %d muestras\n', size(X_train, 1));
fprintf('  âœ“ ValidaciÃ³n:    %d muestras\n', size(X_test, 1));

%% ========================================================================
%  PASO 3: Configurar hiperparÃ¡metros
%  ========================================================================
fprintf('\nPASO 3: Configurando hiperparÃ¡metros del modelo...\n');

% HIPERPARÃMETROS CONFIGURABLES:
n_trees = 100;              % NÃºmero de Ã¡rboles (mÃ¡s = mejor, pero mÃ¡s lento)
min_leaf_size = 5;          % MÃ­nimo de muestras por hoja
max_num_splits = [];        % MÃ¡ximo de divisiones ([] = sin lÃ­mite)
num_variables_to_sample = 'all'; % Variables a considerar por divisiÃ³n

fprintf('  ConfiguraciÃ³n:\n');
fprintf('    - NÃºmero de Ã¡rboles:          %d\n', n_trees);
fprintf('    - TamaÃ±o mÃ­nimo de hoja:      %d\n', min_leaf_size);
fprintf('    - Variables por divisiÃ³n:     %s\n', num_variables_to_sample);

%% ========================================================================
%  PASO 4: Entrenar modelo Random Forest
%  ========================================================================
fprintf('\nPASO 4: Entrenando Random Forest...\n');
fprintf('  â³ Esto puede tomar varios minutos...\n');

tic;

rf_new = TreeBagger(n_trees, X_train, y_train, ...
                    'Method', 'classification', ...
                    'MinLeafSize', min_leaf_size, ...
                    'MaxNumSplits', max_num_splits, ...
                    'NumPredictorsToSample', num_variables_to_sample, ...
                    'OOBPrediction', 'on', ...
                    'OOBPredictorImportance', 'on');

elapsed = toc;

fprintf('  âœ“ Entrenamiento completado en %.1f segundos\n', elapsed);

%% ========================================================================
%  PASO 5: Evaluar rendimiento en validaciÃ³n
%  ========================================================================
fprintf('\nPASO 5: Evaluando rendimiento...\n');

% Predicciones en conjunto de validaciÃ³n
[y_pred, scores] = predict(rf_new, X_test);
y_pred_cat = categorical(y_pred);

% Calcular accuracy
accuracy = sum(y_pred_cat == y_test) / length(y_test) * 100;

fprintf('\n  ğŸ“Š MÃ‰TRICAS DE RENDIMIENTO:\n');
fprintf('    - Accuracy total:     %.2f%%%%\n', accuracy);
fprintf('    - Error OOB:          %.2f%%%%\n', oobError(rf_new) * 100);

% Matriz de confusiÃ³n
fprintf('\n  ğŸ“Š MATRIZ DE CONFUSIÃ“N:\n');
conf_mat = confusionmat(y_test, y_pred_cat);
class_names = categories(y_test);

% Mostrar matriz de confusiÃ³n
fprintf('\n');
fprintf('       Predicho â†’\n');
fprintf('  Real â†“   ');
for i = 1:length(class_names)
    fprintf('%-12s', class_names{i});
end
fprintf('\n');

for i = 1:length(class_names)
    fprintf('  %-10s ', class_names{i});
    for j = 1:length(class_names)
        fprintf('%-12d', conf_mat(i,j));
    end
    fprintf('\n');
end

% MÃ©tricas por clase
fprintf('\n  ğŸ“Š MÃ‰TRICAS POR CLASE:\n');
for i = 1:length(class_names)
    % Precision = VP / (VP + FP)
    precision = conf_mat(i,i) / sum(conf_mat(:,i)) * 100;

    % Recall = VP / (VP + FN)
    recall = conf_mat(i,i) / sum(conf_mat(i,:)) * 100;

    % F1-Score
    f1 = 2 * (precision * recall) / (precision + recall);

    fprintf('    %-20s: Precision=%.1f%%%%, Recall=%.1f%%%%, F1=%.2f\n', ...
            class_names{i}, precision, recall, f1);
end

% Importancia de caracterÃ­sticas
fprintf('\n  ğŸ“Š IMPORTANCIA DE CARACTERÃSTICAS:\n');
importance = oobPermutedPredictorImportance(rf_new);
feature_names = {'RMS_X', 'RMS_Y', 'RMS_Z', 'Kurt_X', 'Kurt_Y', 'Kurt_Z'};

[sorted_imp, idx] = sort(importance, 'descend');
for i = 1:length(sorted_imp)
    bar_len = round(sorted_imp(i) / max(sorted_imp) * 30);
    bar = repmat('â–ˆ', 1, bar_len);
    fprintf('    %-10s: %.4f  %s\n', ...
            feature_names{idx(i)}, sorted_imp(i), bar);
end

%% ========================================================================
%  PASO 6: Visualizar resultados
%  ========================================================================
fprintf('\nPASO 6: Generando visualizaciones...\n');

% Figura 1: Matriz de confusiÃ³n
figure('Position', [100, 100, 700, 600]);
confusionchart(y_test, y_pred_cat);
title('Matriz de ConfusiÃ³n - Conjunto de ValidaciÃ³n', ...
      'FontWeight', 'bold', 'FontSize', 12);
saveas(gcf, 'confusion_matrix.png');

% Figura 2: Importancia de caracterÃ­sticas
figure('Position', [100, 100, 800, 500]);
bar(sorted_imp);
set(gca, 'XTickLabel', feature_names(idx));
ylabel('Importancia');
title('Importancia de CaracterÃ­sticas', 'FontWeight', 'bold');
grid on;
saveas(gcf, 'feature_importance.png');

% Figura 3: Error OOB vs nÃºmero de Ã¡rboles
figure('Position', [100, 100, 800, 500]);
plot(oobError(rf_new), 'LineWidth', 2);
xlabel('NÃºmero de Ã¡rboles');
ylabel('Error OOB');
title('EvoluciÃ³n del Error Out-of-Bag', 'FontWeight', 'bold');
grid on;
saveas(gcf, 'oob_error_evolution.png');

fprintf('  âœ“ GrÃ¡ficas guardadas\n');

%% ========================================================================
%  PASO 7: Guardar modelo
%  ========================================================================
fprintf('\nPASO 7: Guardando modelo...\n');

% Renombrar para compatibilidad con el sistema
rf_ims = rf_new;

% Guardar modelo nuevo
model_file = fullfile('models', 'ims_modelo_nuevo.mat');
save(model_file, 'rf_ims', 'accuracy', 'importance', 'class_names');

fprintf('  âœ“ Modelo guardado: %s\n', model_file);

% Backup del modelo anterior
old_model = fullfile('models', 'ims_modelo_especifico.mat');
if isfile(old_model)
    backup_file = fullfile('models', 'ims_modelo_especifico_BACKUP.mat');
    copyfile(old_model, backup_file);
    fprintf('  âœ“ Backup creado: ims_modelo_especifico_BACKUP.mat\n');
end

fprintf('\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n');
fprintf('â•‘      ENTRENAMIENTO COMPLETADO             â•‘\n');
fprintf('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

fprintf('\nPara usar el nuevo modelo:\n');
fprintf('  1. EvalÃºa el rendimiento: run(''compare_models.m'')\n');
fprintf('  2. Si estÃ¡s satisfecho, reemplaza el modelo:\n');
fprintf('     movefile(''models/ims_modelo_nuevo.mat'', ..\n');
fprintf('              ''models/ims_modelo_especifico.mat'', ''f'')\n');
fprintf('  3. Ejecuta el sistema: IMS_bearing_diagnosis_main()\n\n');
